from datetime import datetime
import os
import faiss
import pickle
import numpy as np
import json
import locale
from dotenv import load_dotenv
from openai import OpenAI
import requests
import gdown
import tempfile

# Carrega vari√°veis de ambiente
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# URLs dos arquivos FAISS no Google Drive
INDEX_URL = "https://drive.google.com/file/d/1cs4c3Uwvn1sEyG4_Dc8rkscJeaxeh4TO/view?usp=share_link"
PKL_URL = "https://drive.google.com/file/d/1YT_OgYIzPh9P72cLhtEeLDnkxYKov6Ku/view?usp=share_link"

# Caminhos locais para salvar os arquivos baixados
ARQUIVO_INDEX = os.path.join(os.path.dirname(__file__), 'vetor_univesp.index')
ARQUIVO_META = os.path.join(os.path.dirname(__file__), 'vetor_univesp.pkl')

def download_file_from_google_drive(url, output_path):
    """Baixa arquivos do Google Drive usando gdown."""
    try:
        gdown.download(url, output_path, quiet=False, fuzzy=True)
        return True
    except Exception as e:
        print(f"Erro ao baixar arquivo: {e}")
        return False

# Tenta baixar e carregar √≠ndice FAISS e metadados, ou cria um modelo simulado se n√£o conseguir
try:
    # Baixa os arquivos se eles n√£o existirem localmente
    if not os.path.exists(ARQUIVO_INDEX):
        print(f"Baixando arquivo de √≠ndice FAISS de {INDEX_URL}")
        download_success = download_file_from_google_drive(INDEX_URL, ARQUIVO_INDEX)
        if not download_success:
            raise Exception("N√£o foi poss√≠vel baixar o arquivo de √≠ndice")
    
    if not os.path.exists(ARQUIVO_META):
        print(f"Baixando arquivo de metadados FAISS de {PKL_URL}")
        download_success = download_file_from_google_drive(PKL_URL, ARQUIVO_META)
        if not download_success:
            raise Exception("N√£o foi poss√≠vel baixar o arquivo de metadados")
    
    # Carrega os arquivos
    index = faiss.read_index(ARQUIVO_INDEX)
    with open(ARQUIVO_META, 'rb') as f:
        metadados = pickle.load(f)
    
    print("Arquivos FAISS carregados com sucesso!")
    
except Exception as e:
    # Cria um √≠ndice FAISS simples para simula√ß√£o
    print(f"Erro ao carregar arquivos FAISS: {e}")
    print("Criando √≠ndice simulado.")
    dimension = 1536  # Dimens√£o dos embeddings da OpenAI
    index = faiss.IndexFlatL2(dimension)
    metadados = [
        """Data: 15/05/2023, Hora: 10:30, Temperatura: 22.5¬∞C, Umidade: 65%, Press√£o: 1013.2 hPa, Luminosidade: 680 lux.
        Condi√ß√µes ideais para ciclismo, com c√©u parcialmente nublado proporcionando boa visibilidade.
        """,
        """Data: 20/06/2023, Hora: 15:45, Temperatura: 28.3¬∞C, Umidade: 48%, Press√£o: 1010.5 hPa, Luminosidade: 850 lux.
        Clima quente mas com umidade moderada, recomendada hidrata√ß√£o frequente durante o percurso.
        """,
        """Data: 05/07/2023, Hora: 08:15, Temperatura: 18.2¬∞C, Umidade: 75%, Press√£o: 1015.8 hPa, Luminosidade: 450 lux.
        Manh√£ com neblina leve, visibilidade reduzida em algumas √°reas mais baixas da cidade.
        """,
        """Data: 10/08/2023, Hora: 17:30, Temperatura: 24.1¬∞C, Umidade: 55%, Press√£o: 1012.3 hPa, Luminosidade: 380 lux.
        Final de tarde com condi√ß√µes agrad√°veis, vento leve de sudeste favorecendo percursos na dire√ß√£o norte.
        """,
        """Data: 22/09/2023, Hora: 12:00, Temperatura: 26.8¬∞C, Umidade: 45%, Press√£o: 1009.7 hPa, Luminosidade: 920 lux.
        Meio-dia com sol forte, recomendado uso de protetor solar e √≥culos de prote√ß√£o UV.
        """
    ]
    # Criamos embeddings simulados para cada metadado
    dummy_embeddings = np.random.random((len(metadados), dimension)).astype('float32')
    index.add(dummy_embeddings)

# Vari√°veis globais para uso externo
data = ""
dados_sensor = {}

# Temperaturas hist√≥ricas simuladas para S√£o Jos√© dos Campos (m√≠nima e m√°xima mensal)
temperaturas_historicas = {
    1: {"min": 18.0, "max": 30.0, "media": 24.5},  # Janeiro
    2: {"min": 19.0, "max": 31.0, "media": 25.0},  # Fevereiro
    3: {"min": 18.0, "max": 30.0, "media": 24.0},  # Mar√ßo
    4: {"min": 16.5, "max": 28.0, "media": 22.5},  # Abril
    5: {"min": 14.0, "max": 26.0, "media": 20.0},  # Maio
    6: {"min": 12.0, "max": 25.0, "media": 18.5},  # Junho
    7: {"min": 11.0, "max": 24.0, "media": 17.5},  # Julho
    8: {"min": 12.0, "max": 26.0, "media": 19.0},  # Agosto
    9: {"min": 14.0, "max": 27.0, "media": 20.5},  # Setembro
    10: {"min": 16.0, "max": 28.0, "media": 22.0}, # Outubro
    11: {"min": 17.0, "max": 29.0, "media": 23.0}, # Novembro
    12: {"min": 18.0, "max": 30.0, "media": 24.0}  # Dezembro
}

def comparar_temperatura_historica(temperatura_atual):
    """
    Compara a temperatura atual com os dados hist√≥ricos para o m√™s atual
    
    Args:
        temperatura_atual (float): Temperatura atual em graus Celsius
        
    Returns:
        dict: Dicion√°rio com status da temperatura e compara√ß√£o hist√≥rica
    """
    mes_atual = datetime.now().month
    dados_mes = temperaturas_historicas.get(mes_atual, {"min": 15.0, "max": 28.0, "media": 22.0})
    
    # Verificar onde a temperatura se encaixa
    if temperatura_atual < dados_mes["min"]:
        status = "abaixo"
        diferenca = abs(temperatura_atual - dados_mes["min"])
        percentual = round((diferenca / dados_mes["min"]) * 100, 1)
    elif temperatura_atual > dados_mes["max"]:
        status = "acima"
        diferenca = abs(temperatura_atual - dados_mes["max"])
        percentual = round((diferenca / dados_mes["max"]) * 100, 1)
    else:
        status = "dentro"
        # Calcular o qu√£o pr√≥ximo est√° da m√©dia
        diferenca = abs(temperatura_atual - dados_mes["media"])
        amplitude = (dados_mes["max"] - dados_mes["min"]) / 2
        percentual = round((diferenca / amplitude) * 100, 1)
    
    return {
        "status": status,
        "temperatura_atual": temperatura_atual,
        "min_historica": dados_mes["min"],
        "max_historica": dados_mes["max"],
        "media_historica": dados_mes["media"],
        "diferenca": diferenca,
        "percentual": percentual
    }

def executar_analise():
    global data, dados_sensor

    dt = datetime.now()
    data_hora = dt.strftime("%d/%m/%Y %H:%M")
    data = dt.strftime("%d/%m/%Y")

    try:
        locale.setlocale(locale.LC_TIME, 'pt_BR.UTF-8')
        dia_semana = dt.strftime('%A').capitalize()
    except:
        try:
            locale.setlocale(locale.LC_TIME, 'pt_BR')
            dia_semana = dt.strftime('%A').capitalize()
        except:
            dia_semana = "Indefinido"

    relatorio_completo = ""
    relatorio_completo += f"üö≤ **Relat√≥rio de An√°lise de Pedalada** üö≤\n"
    relatorio_completo += f"üìÖ Data/Hora: {data_hora} ({dia_semana})\n\n"

    # === Simula sensores com LLM ===
    prompt = """Gere dados aleat√≥rios realistas para sensores em S√£o Jos√© dos Campos. 
    Retorne um JSON com:
    - "temperatura": valor em ¬∞C (float)
    - "umidade": percentual (float)
    - "pressao": valor em hPa (float)
    - "luminosidade": valor em lux (float)"""

    try:
        # the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
        # do not change this unless explicitly requested by the user
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": "Voc√™ √© um gerador de dados de sensores."},
                {"role": "user", "content": prompt}
            ]
        )
        sensor_data = json.loads(response.choices[0].message.content)

        temperatura = float(sensor_data['temperatura'])
        umidade = float(sensor_data['umidade'])
        pressao = float(sensor_data['pressao'])
        luminosidade = float(sensor_data['luminosidade'])

        dados_sensor = {
            "data_hora": data_hora,
            "temperatura": temperatura,
            "umidade": umidade,
            "pressao": pressao,
            "luminosidade": luminosidade,
            "hora_num": round(dt.hour + dt.minute / 60, 2)
        }

        relatorio_completo += "üå°Ô∏è **Dados dos Sensores**:\n"
        relatorio_completo += f"- Temperatura: {temperatura}¬∞C\n"
        relatorio_completo += f"- Umidade: {umidade}%\n"
        relatorio_completo += f"- Press√£o: {pressao} hPa\n"
        relatorio_completo += f"- Luminosidade: {luminosidade} lux\n\n"

    except Exception as e:
        relatorio_completo += f"‚ùå Erro na gera√ß√£o de dados: {e}\n"
        return relatorio_completo

    # === Busca FAISS ===
    texto_consulta = (
        f"Temperatura: {temperatura}¬∞C, Umidade: {umidade}%, "
        f"Press√£o: {pressao} hPa, Luminosidade: {luminosidade} lux, "
        f"Hora_num: {dados_sensor['hora_num']}"
    )

    try:
        def gerar_embedding(texto: str) -> np.ndarray:
            # the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
            # do not change this unless explicitly requested by the user
            response = client.embeddings.create(
                input=[texto],
                model="text-embedding-ada-002"
            )
            return np.array(response.data[0].embedding, dtype='float32')

        vetor = gerar_embedding(texto_consulta)
        vetor = np.expand_dims(vetor, axis=0)
        distancias, indices = index.search(vetor, 5)
        similares = [metadados[i] for i in indices[0]]

        relatorio_completo += "üîç **Registros Hist√≥ricos Similares**:\n"
        registros_texto = ""
        for i, item in enumerate(similares, 1):
            registros_texto += f"\nüîπ Registro {i}:\n{item.strip()}\n"
        relatorio_completo += registros_texto + "\n"

    except Exception as e:
        relatorio_completo += f"\n‚ùå Erro na busca FAISS: {e}\n"
        return relatorio_completo

    # Obter an√°lise da temperatura para comparar com dados hist√≥ricos
    try:
        analise_temperatura = comparar_temperatura_historica(temperatura)
        analise_temp_texto = ""
        
        if analise_temperatura["status"] == "dentro":
            analise_temp_texto = f"""
üìä **An√°lise clim√°tica hist√≥rica**:
A temperatura atual de {analise_temperatura['temperatura_atual']:.1f}¬∞C est√° dentro da faixa hist√≥rica para este m√™s 
(m√≠nima: {analise_temperatura['min_historica']}¬∞C, m√°xima: {analise_temperatura['max_historica']}¬∞C).
Est√° {analise_temperatura['diferenca']:.1f}¬∞C distante da m√©dia hist√≥rica de {analise_temperatura['media_historica']}¬∞C.
"""
        elif analise_temperatura["status"] == "acima":
            analise_temp_texto = f"""
üìä **An√°lise clim√°tica hist√≥rica**:
‚ö†Ô∏è A temperatura atual de {analise_temperatura['temperatura_atual']:.1f}¬∞C est√° {analise_temperatura['diferenca']:.1f}¬∞C ACIMA 
da m√°xima hist√≥rica de {analise_temperatura['max_historica']}¬∞C para este m√™s.
Isso representa {analise_temperatura['percentual']}% acima do normal, exigindo cuidados extras com hidrata√ß√£o.
"""
        else:  # abaixo
            analise_temp_texto = f"""
üìä **An√°lise clim√°tica hist√≥rica**:
‚ùÑÔ∏è A temperatura atual de {analise_temperatura['temperatura_atual']:.1f}¬∞C est√° {analise_temperatura['diferenca']:.1f}¬∞C ABAIXO 
da m√≠nima hist√≥rica de {analise_temperatura['min_historica']}¬∞C para este m√™s.
Isso representa {analise_temperatura['percentual']}% abaixo do normal, recomendando vestimenta adequada.
"""
    except Exception as e:
        print(f"Erro ao gerar an√°lise de temperatura: {str(e)}")
        analise_temp_texto = ""

    # === An√°lise com LLM ===
    prompt_analise = f"""
Voc√™ √© um especialista em clima e ciclismo urbano de S√£o Jos√© dos Campos.

üìå Dados atuais:
- Data/Hora: {data_hora}
- Dia da semana: {dia_semana}
- Temperatura: {temperatura}¬∞C
- Umidade: {umidade}%
- Press√£o: {pressao} hPa
- Luminosidade: {luminosidade} lux

{analise_temp_texto}

Registros hist√≥ricos similares:
{registros_texto}

üß† Tarefa:
1. An√°lise DETALHADA com MUITOS N√öMEROS E COMPARA√á√ïES:
   - Compare a temperatura atual ({temperatura}¬∞C) com dados hist√≥ricos e explique o impacto no ciclismo
   - Analise se a umidade de {umidade}% est√° adequada para ciclismo (ideal: 40-70%)
   - Verifique se a press√£o de {pressao} hPa indica estabilidade ou mudan√ßas clim√°ticas
   - Avalie se a luminosidade de {luminosidade} lux √© segura para pedalada nesse hor√°rio

2. Avalie seguran√ßa espec√≠fica para pedalar considerando:
   - Fatores ambientais: temperatura, umidade, press√£o, e luminosidade para o hor√°rio
   - Se o hor√°rio √© prop√≠cio para pedalada (manh√£, tarde, noite)
   - Se h√° algum alerta ou cuidado especial com base nos dados

3. Recomenda√ß√£o detalhada para o ciclista incluindo:
   - Tipo de vestimenta adequada para as condi√ß√µes (baseada na temperatura e umidade)
   - Quantidade de hidrata√ß√£o recomendada (baseada na temperatura e umidade)
   - Sugest√µes espec√≠ficas para conforto e seguran√ßa

Use muitos dados num√©ricos e fa√ßa compara√ß√µes detalhadas entre valores atuais e valores ideais ou hist√≥ricos.
"""

    try:
        # the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
        # do not change this unless explicitly requested by the user
        resposta = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Especialista em clima e ciclismo urbano."},
                {"role": "user", "content": prompt_analise}
            ]
        )
        analise_final = resposta.choices[0].message.content.strip()
        relatorio_completo += "üß† **An√°lise Final e Recomenda√ß√£o**:\n"
        relatorio_completo += analise_final + "\n"

    except Exception as e:
        relatorio_completo += f"\n‚ùå Erro na gera√ß√£o da an√°lise final: {e}\n"

    return relatorio_completo
